{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Different Train and Test File\n",
    "# TensorFlow and Keras to build CNN Image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have only 2 classes - Mountain bike and Road bike\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# The training images are processed converting them to 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size. Must be evenly dividable by dataset sizes.\n",
    "BATCH_SIZE = 10        # Total training images = 140\n",
    "\n",
    "# Maximum number of training steps.\n",
    "MAX_STEPS = 2000\n",
    "\n",
    "# Directory to put the training data.\n",
    "TRAIN_DIR='mountain-and-road/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator().flow_from_directory(TRAIN_DIR, target_size=(28,28), classes=['mountain','road'], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if(ims.shape[-1]!=3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims) //rows if len(ims)%2 ==0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_inference(X):\n",
    "\n",
    "    K=4\n",
    "    L=8\n",
    "    M=12\n",
    "\n",
    "    W1 = tf.Variable(tf.truncated_normal([5, 5, 3, K], stddev=0.1))\n",
    "    B1 = tf.Variable(tf.ones([K])/10)\n",
    "    W2 = tf.Variable(tf.truncated_normal([4, 4, 4, L], stddev=0.1))\n",
    "    B2 = tf.Variable(tf.ones([L])/10)\n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, 8, M], stddev=0.1))\n",
    "    B3 = tf.Variable(tf.ones([M])/10)\n",
    "    \n",
    "    N=200\n",
    "\n",
    "    W4 = tf.Variable(tf.truncated_normal([7*7*M, N], stddev=0.1))\n",
    "    B4 = tf.Variable(tf.ones([N])/10)\n",
    "    W5 = tf.Variable(tf.truncated_normal([N, 2], stddev=0.1))\n",
    "    B5 = tf.Variable(tf.zeros([2])/10)\n",
    "    \n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME') + B1)  \n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, 2, 2, 1], padding='SAME') + B2)\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, 2, 2, 1], padding='SAME') + B3)\n",
    "\n",
    "    YY = tf.reshape(Y3, shape=[-1, 7*7*M])\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    Y  = tf.nn.softmax(tf.matmul(Y4, W5) + B5)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_training(y_, Y):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Y))\n",
    "    \n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "    \n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        \n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-d67d10cf46c1>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_graph = tf.Graph()\n",
    "with cnn_graph.as_default():\n",
    "    # Generate placeholders for the images and labels.\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 28, 28, 3])                                      \n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "    tf.add_to_collection(\"images\", X)  # Remember this Op.\n",
    "    tf.add_to_collection(\"labels\", y_)  # Remember this Op.\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    Y = cnn_inference(X)\n",
    "    tf.add_to_collection(\"Y\", Y)  # Remember this Op.\n",
    "\n",
    "    # Add to the Graph the Ops that calculate and apply gradients.\n",
    "    train_op, loss = cnn_training(y_, Y)\n",
    "\n",
    "    # Add the variable initializer Op.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 0.71\n",
      "Step 1000: loss = 0.71\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=cnn_graph) as sess:\n",
    "    # Run the Op to initialize the variables.\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the training loop.\n",
    "    for step in xrange(MAX_STEPS):\n",
    "        # Read a batch of images and labels.\n",
    "        imgs, labels = next(train_batches)\n",
    "\n",
    "        _, loss_value = sess.run([train_op, loss],\n",
    "                                 feed_dict={X: imgs,\n",
    "                                            y_:labels})\n",
    "\n",
    "        losses.append(loss_value)\n",
    "        # Print out loss value.\n",
    "        if step % 1000 == 0:\n",
    "            print('Step %d: loss = %.2f' % (step, loss_value))\n",
    "\n",
    "    # Write a checkpoint.\n",
    "    checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "    saver.save(sess, checkpoint_file, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
